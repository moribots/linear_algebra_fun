# linear_algebra_fun
A  place to brush up on practical applications of linear algebra.

# Project 1 - Linear Regression
Predicting y from x. 
y = mx + b + Ïµ
where Ïµ is random noise

## 1. Matrix Form:
y = XÎ² + Ïµ

where:
y is the target vector.

X is the design matrix (including a column of ones for the intercept).

Î² is the vector of coefficients to solve for.

## 2. Closed-form solution (Normal Equation):
Î² = (ğ‘‹.T ğ‘‹).inv() * ğ‘‹.T y


## 3. Implement gradient descent to minimize the mean squared error:
J(Î²) = (1/2n) âˆ¥XÎ² âˆ’ yâˆ¥^2


Update rule:
Î²k + 1 = Î²k âˆ’nâˆ‡J(Î²k)

where:

âˆ‡J(Î²) = (1/n) X.T(XÎ² âˆ’ y)


## 4. Compare Solutions

Compare the coefficients Î² = [m, b] from 2. and 3.

Plot above to visualize.


## 5. Analyze Performance
Compute MSE.
